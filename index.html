<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Siyi Du</title>
  
  <meta name="author" content="Siyi Du">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes" />  -->
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <script type="text/javascript" src="jquery.js"></script>
  <link rel="shortcut icon" href="images/cat.ico">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163347198-1"></script>
  <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
          dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "UA-163347198-1");
  </script>

  <script>
      function displayBlock(div_id) {
          var x = document.getElementById(div_id);
          if (x.style.display === "none") {
              x.style.display = "block";
          } else {
              x.style.display = "none";
          }
      }
  </script>

  <script>
      function scroll_to(div_id) {
          const x = document.getElementById(div_id);
          x.scrollIntoView();
      }
  </script>

  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Siyi Du</name>
              </p>
              <p>I am a research master student at the Biomedical Signal and Image Computing Laboratory
                (<a href="https://bisicl.ece.ubc.ca/">BiSICL</a>), 
                University of British Columbia under Prof. Rafeef Garbi, where I work on Medical Imaging and Deep Learning.
              </p>
              <p>
              <p> I obtained my bachelor degree in Automation Science (Pattern Recognition direction) from Beihang University at 2021. 
                <!-- At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>. -->
              </p>
              <p style="text-align:center">
                <a href="data/siyi_email.txt">Email</a> &nbsp/&nbsp
                <a href="data/CV_Siyi_Du.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=zsOt8MYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/siyi-du-453280205/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/siyi-wind">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo_siyi.jpg"><img style="width:65%;max-width:65%;
                position:relative;left:15%" alt="profile photo" src="images/photo_siyi.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>



          <!-- News -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>News &#128008;</heading>
              </td>
            </tr>
          </tbody></table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <p "font-size:60px">
                    &#11088; &nbsp; <strong>July-2023</strong> &nbsp; Two papers (AViT and Continual-GEN) are accepted by MICCAI ISIC Workshop 2023!! 
                    <br>    
                    <p></p> 
                  &#11088; &nbsp; <strong>June-2023</strong> &nbsp; One paper (MDViT) is accepted by MICCAI 2023!!</p>      
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>



        <!--research project  -->
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, deep learning, medical imaging, generalizable learning, and fairness. Currently I am 
                focusing on alleviating vision transformers' data hunger in medical image segmentation tasks. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <!-- AViT -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/siyi_MICCAIW2023_AViT.png' width="110%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/abs/2307.13897">
                <papertitle>AViT: Adapting Vision Transformers for Small Skin Lesion Segmentation Datasets</papertitle>
              </a>
              <br>
              <strong>Siyi Du</strong>,
              <a href="https://scholar.google.com/citations?user=M-hb1W0AAAAJ&hl=en&oi=ao">Nourhan Bayasi</a>,
							<a href="https://www.medicalimageanalysis.com/">Ghassan Hamarneh</a>, 
              <a href="https://bisicl.ece.ubc.ca/rafeef/">Rafeef Garbi</a>
              <br>
              <em>MICCAI ISIC Workshop</em>, 2023
              <br>
              <a href="http://arxiv.org/abs/2307.13897">arXiv</a>
              /
              <a href="https://github.com/siyi-wind/AViT">code</a>
              <!-- /
              <a href="https://youtu.be/ebY_k48Y21o">video</a>  -->
              <p></p>
              <p>
              We propose AViT, a novel efficient strategy to mitigate ViTs' data-hunger by transferring any pre-trained ViTs to the SLS task based on parameter-efficient fine-tuning.
              </p>
            </td>
          </tr>

          <!-- MDViT -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/siyi_MICCAI2023_MDViT.png' width="110%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2307.02100">
                <papertitle>MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets</papertitle>
              </a>
              <br>
              <strong>Siyi Du</strong>,
              <a href="https://scholar.google.com/citations?user=M-hb1W0AAAAJ&hl=en&oi=ao">Nourhan Bayasi</a>,
							<a href="https://www.medicalimageanalysis.com/">Ghassan Hamarneh</a>, 
              <a href="https://bisicl.ece.ubc.ca/rafeef/">Rafeef Garbi</a>
              <br>
              <em>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2307.02100">arXiv</a>
              /
              <a href="https://github.com/siyi-wind/MDViT">code</a>
              <!-- /
              <a href="https://youtu.be/ebY_k48Y21o">video</a>  -->
              <p></p>
              <p>
              We are the first to alleviate ViTs' data-hunger by multi-domain learning. We proposed MDViT, 
              with a novel domain adapter to counteract negative knowledge transfer and with mutual knowledge distillation to enhance representation learning.
              </p>
            </td>
          </tr>

          <!-- FairDisCo -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/siyi_ECCVW2022_FairDisCo.png' width="110%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-25069-9_13">
                <papertitle>FairDisCo: Fairer AI in Dermatology 
                  via Disentanglement Contrastive Learning</papertitle>
              </a>
              <br>
              <strong>Siyi Du</strong>,
              <a href="https://www.linkedin.com/in/benjamin-hers/">Ben Hers</a>,
              <a href="https://scholar.google.com/citations?user=M-hb1W0AAAAJ&hl=en&oi=ao">Nourhan Bayasi</a>,
							<a href="https://www.medicalimageanalysis.com/">Ghassan Hamarneh</a>, 
              <a href="https://bisicl.ece.ubc.ca/rafeef/">Rafeef Garbi</a>
              <br>
              <em>European Conference on Computer Vision (ECCV) ISIC Workshops</em>, 2022, <strong>Best Paper Award</strong>
              <br>
              <a href="https://arxiv.org/abs/2208.10013">arXiv</a>
              /
              <a href="https://github.com/siyi-wind/FairDisCo">code</a>
              /
              <a href="https://youtu.be/ebY_k48Y21o">video</a> 
              <p></p>
              <p>
              We investigated skin-type fairness in skin lesion classification datasets and models. We 
              proposed a novel deep neural network, FairDisCo, featuring disentangled representation learning 
              and contrastive learning to promote fairness and boost classification accuracy.
              </p>
            </td>
          </tr>

          <!-- KBGN -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/siyi_ACMMM2020_KBGN.png' width="110%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413826">
                <papertitle>KBGN: Knowledge-Bridge Graph Network for Adaptive
                  Vision-Text Reasoning in Visual Dialogue</papertitle>
              </a>
              <br>
              <a href="https://jxze.github.io/">Xiaze Jiang</a>,
              <strong>Siyi Du</strong>,
              <a href="http://dsd.future-lab.cn/members/qin.html">Zengchang Qin</a>,
              Yajing Sun,
							<a href="https://mmlab-iie.github.io/">Jing Yu</a>
              <br>
              <em>ACM International Conference on Multimedia (ACM MM)</em>, 2020, <strong>Oral</strong>
              <br>
              <a href="https://arxiv.org/abs/2008.04858">arXiv</a>
              <!-- <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
              We proposed a novel Knowledge-Bridge Graph Network (KBGN) model by using graph to bridge 
              the cross-modal semantic relations between vision and text knowledge in fine granularity.
              </p>
            </td>
          </tr>
        </tbody></table>

        <p>
        <!--course project  -->
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Recent Projects</heading>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/siyi_course2022_BATU.png' width="110%">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="data/siyi_course2022_BATUS.pdf">
                  <papertitle>Skin Lesion Segmentation based on Transformer</papertitle>
                </a>
                <br>
                <strong>Siyi Du</strong>,
                <a href="https://www.linkedin.com/in/benjamin-hers/">Ben Hers</a>
                <br>                
                <em>UBC CPSC533R Visual AI</em>, supervised by Prof.
                <a href="https://www.cs.ubc.ca/~rhodin/web/">Helge Rhodin</a>, 2022
                <br>
                <a href="data/siyi_course2022_BATUS.pdf">report</a>
                <p></p>
                <p>
                We developed a hybrid transformer architecture, BATU, with a transformer bottleneck to improve 
                the skin lesion segmentation performance and applied a boundary-aware attention gate 
                to mitigate ambiguous boundaries.
                </p>
              </td>
            </tr>
          
           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/siyi_course2022_HART.png' width="110%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/siyi_course2022_HART.pdf">
                <papertitle>3D Ultrasound Segmentation using Transformers</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/benjamin-hers/">Ben Hers</a>, 
              <strong>Siyi Du</strong>
              <br>     
              <em>UBC EECE571F Deep Learning with Structures</em>, supervised by Prof.
              <a href="https://lrjconan.github.io/index.html">Renjie Liao</a>, 2022
              <br>
              <a href="https://lrjconan.github.io/DL-structures/assets/sample_reports_2021/report_04.pdf">report</a>
              <p></p>
              <p>
              We combined both aspects from CNNs and Transformers in a hybrid model 
              which utilizes axial attention to efficiently and effectively segment bones from 3D ultrasound scans.
              </p>
            </td>
          </tr>
         </table>            -->
        

         <!-- internship -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Intership</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/siyi_kent-state-university-stacked-logo.jpeg" width="110%"></td>
            <td width="75%" valign="center">
              <papertitle>Adaptation of Robot to New Environment Based on Self-Supervised Learning</papertitle>
              <br>
              <em>Summer Research Intern</em>, supervised by 
              <a href="https://ruiliurobotics.weebly.com/">Rui Liu</a>, Kent State University, 2020
              <br>
              <p>
              We developed an adaptive robot based on self-supervised learning that could implement tasks in a target environment 
              after training on a source environment.
            </td>
          </tr>
          </table>
   


          <!-- misc -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Misc</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/siyi_award_logo.jpeg" width="110%"></td>
              <td width="75%" valign="center">
                <strong>Awards</strong>
                <br>
                The Graduate Support Initiative (GSI) Award in UBC, 2023
                <br>
                The Research Assistant Scholarship in UBC, 2021-2022
                <br>
                The International Tuition Awards in UBC, 2021-2022
                <br>
                Meritorious Winner, Mathematical Contest in Modeling in USA, 2020
                <br>
                The 1st Prize of National Mathematics Competition for College Students, 2018
                <br>
                The National Encouragement Scholarship in China, 2018-2020
                <br>
                The Prize of Outstanding Student in Beihang University, 2018-2019
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/siyi_hobby_log.png" width="110%">
              </td>
              <td width="75%" valign="center">
                <strong>Hobbies</strong>
                <br>
                I like photography and yoga. Some of my photos were curated on 
                <a href="https://unsplash.com/@siyiwind">Unsplash</a>.
              </td>
            </tr>
            </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                Website template is from 
                <a href="https://jonbarron.info/">template 1</a> and 
                <a href="https://jxze.github.io/">template 2</a>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

      </td>
    </tr>
  </table>
</body>

</html>
